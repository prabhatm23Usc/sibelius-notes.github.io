---
title: CS 341 - Algorithms
layout: mdtoc
---
post mid material: starting from graph algorithms. Notes are a mix of different offerings...

[pseudocode.js](https://github.com/SaswatPadhi/pseudocode.js/tree/master)

# Graph Algorithms
## Basic
directed, adjacent, incident, indegree, outdegree, path, cycle, tree, connected, connected component.

A **simple** path does not repeat vertices. A **simple** cycle does not repeat vertices.


Our algorithms will be for abstract graphs. Two ways to represent:
- adjacency matrix: space &#92;(O(n^2) &#92;)
- adjacency lists: space &#92;(O(n+m) &#92;)

|basic operations  | adj matrix| adj lists|
| :------------- | :------------- | :-- |
| list &#92;(v &#92;)'s neighbours| &#92;(\Theta(n) &#92;) | &#92;(\Theta(1+\deg(v)) &#92;)|
| list all edges | &#92;(\Theta(n^2) &#92;) | &#92;(\Theta(n+m) &#92;) |
| is &#92;((u,v)\in E &#92;) | &#92;(\Theta(1) &#92;) | &#92;(\Theta(1+\deg(u)) &#92;) |

where the last complexity &#92;(\Theta(1+\deg(u)) &#92;)  can be reduced to &#92;(O(1) &#92;)
with (sophisiticated) hashing.

For algorithm in this course, we will use adjacency lists.

## Exploring Graphs

### BFS
Cautious search: check everything one edge away, then two...

It takes &#92;(O(n+m) &#92;) time: we explore each vertex once and check all incident edges: &#92;(O(n+\sum_{v\in V} \deg(v))=O(n+m) &#92;). Recall &#92;(\sum_{v\in V} \deg(v) = 2m &#92;).

**Properties**
- The parent pointers create a directed tree.
- &#92;(u &#92;) is connected to &#92;(v_0 &#92;) iff BFS from &#92;(v_0 &#92;) reaches &#92;(u &#92;).
- The level of a vertex &#92;(v &#92;) = length of shortest path from &#92;(v_0 &#92;) to &#92;(v &#92;).

**Consequences**
1. BFS from &#92;(v_0 &#92;) finds the connected component of &#92;(v_0 &#92;)
2. BFS finds shortest paths (# edges) from &#92;(v_0 &#92;)

**BFS to test bipartiteness**
definition omitted... it cannot have an odd cycle.

### DFS
Bold search: go as far as you can; when there's nothing new to discover, retrace your steps to find sth new.

Note: orders depend on order in adjacency list. Use a stack to store vertices that have been discovered but must still be explored. So we use a recursive algorithm where stack is implicit.

Runtime: &#92;(O(n+m) &#92;)

All non-tree edges join ancestor and descendant.

Here we abbr: &#92;(d(v)=discovers(v), f(v)=finish(v) &#92;). If &#92;(d(v)<d(u) &#92;) then we have only two possiblities: either nested or disjoint
```
[       ]       [       ]           OR      [        [       ]       ]
d(v)    f(v)    d(u)    f(u)                d(v)     d(u)    f(u)    f(v)
```
because interval &#92;(d(v),f(v) &#92;) is time on stack.

**DFS to find 2-connected components**. Involve some defns of cut-vertex. Not covered in D.R. Stinson's slide.
- **Claim**: The root is a cut vertex iff it has &#92;(> 1&#92;) child.
- **Lemma**: non-root &#92;(v &#92;) is a cut vertex iff &#92;(v &#92;) has a subtree &#92;(T &#92;) with non-tree edge going to an ancestor of &#92;(v &#92;).

Now let's DFS on **Directed Graphs**.
- **tree edges** form a forest of trees.
- **forward edges** are from a vertex to a descendant in the tree.
- **cross edges** are from node a to node b where the subtrees rooted at a and b are disjoint.
- **back edges** are from a vertex to an ancestor.

Then in DFS, we label the edges:
- if u not finished, then (v, u) is back edge
- else if &#92;(d(u) > d(v)&#92;) then (v, u) forward edge
- else if &#92;(d(u) < d(v) &#92;) then (v, u) cross edge

**Applications of DFS**
1. detecting cycles in directed graphs.<br>
**Lemma**: A directed graph has a directed cycle iff DFS has a back edge.
2. Topological sort of a directed **acyclic** (no directed cycle) graph. Edge &#92;((a,b) &#92;) means &#92;(a &#92;) must come before &#92;(b &#92;). (e.g. job scheduling). Find a linear order of vertices satisfying all edges. (possible if no directed cycle).
<br>**One solution**: find vertex &#92;(v &#92;) with no in-edge. Remove &#92;(v &#92;) and repeat. &#92;(O(n+m) &#92;)
<br>**Solution using DFS**: also &#92;(O(n+m) &#92;) use reverse of finish order.
3. Finding strongly connected components in a directed graph.
<br> Strongly connected = for all vertices &#92;(u,v &#92;) there is a path &#92;(u\to v &#92;) and a path &#92;(v\to u &#92;).
<br> **Claim**  Let &#92;(s &#92;) be a vertex. (G &#92;) is strongly connected if for all vertices &#92;(v &#92;) there is a path &#92;(s\to v &#92;) and a path &#92;(v\to s &#92;).
<br>To test if there's a path &#92;(s\to v\quad \forall v &#92;), do DFS(s). How can we test it there's a path &#92;(v\to s\quad \forall v &#92;)? Reverse edge directions and do DFS(s). **Neat!**.

More generally, a digraph can be partitioned to strongly connected components.

<img src="/pics/DAG.png">

Picture from [here](https://www.cs.cmu.edu/~15451-f17/lectures/lec11-DFS-strong-components.pdf).

Contracting strongly connected components gives acyclic graph.

*How to find strongly connected components?*

Idea: vertices 1 ... n.
<br>Run DFS (vertex ordering resolves what vertex comes next).
<br> Let finish order be &#92;(f_1 f_2 \ldots f_2 &#92;).
<br>&#92;(G^R=G &#92;) with all edges reversed.
<br>run DFS &#92;(G^R &#92;) with vertex order &#92;(f_n f_{n-1}\ldots f_1 &#92;)

Trees in 2nd DFS are exactly the strongly connected components.

**Shairi's Algorithm to Find the Strongly Connected Components**
1. Perform a depth-first search of G, recording the finishing times *f[v]* for all vertices v.
2. Construct a directed graph H from G by **reversing** the direction of all edges in G.
3. Perform a depth-first search of H, considering the vertices in **decreasing** order of the values *f[v]* computed in step 1.
4. The strongly connected components of G are the trees in the depth-first forest constructed in step 3.

## Minimum Spanning Tree
Given a graph &#92;(G=(V,E) &#92;) with weights &#92;(\omega:E\to \mathbb R^{\ge 0} &#92;) one the edges find a subset of the edges that connected all the vertices and has minimum weight. The edge subset will be a tree, called the **minimum spanning tree**.

Greedy alg will find min spanning trees with different implementation challenges.
- add cheapest edge first, never build a cycle: Kruskal's alg.
- grow connected graph from one vertex: Prim's alg.

### Kruskal's Algorithm
```
Order edges by weight
    w(e_i) <= w(e_{i+1})
T <- ∅
for i = 1..m
    if e_i does not make a cycle with T then
        T <- T ∪ {e_i}
endfor
```
 &#92;(O(m\log m) = O(m\log n) &#92;) to sort edges because &#92;(m\le n^2 &#92;). Then we need to  maintain connected components as we add edges. So it is union-find problem.

#### Union-Find Problem
Maintain a collection of disjoint sets.

Operations:
- `Find(x)` - which set contains element x?
- `Union` - unite two sets.

Every tree contains a leader vertex. We construct an auxiliary array &#92;(L &#92;). From &#92;(v &#92;), follow a directed path &#92;(v\to L[v]\to L[L[v]] \to \ldots &#92;) until we reach &#92;(w &#92;) with &#92;(L[w]=w &#92;). Then &#92;(w=find(v) &#92;).

> Or keep array `S[1..n]`, `S[i]` = component  of element i and keep linked list in each set.

Then `find` is &#92;(O(1) &#92;). Union: must joint 2 linked lists &#92;(O(1) &#92;) and rename one of the two sets. So &#92;(O(n) &#92;) in worst case. BUT renaming smaller set does better! If an element's set number changes, then its set (more than) doubles. This happens &#92;(\le  \log n&#92;)  times. Therefore total renaming work is &#92;(O(n\log n) &#92;). Thus total runtime
&#92;[
    \underbrace{O(m\log n)}_ {sort} +
    \underbrace{O(m)}_ {finds} +
    \underbrace{O(n\log n)}_ {unions}
    = O(m\log n)
&#92;]
Assuming &#92;(G &#92;) is connected, so &#92;(m\ge n-1 &#92;).

### Prim's Algorithm
```
initialize C <- {S}, T <- ∅
while C != V
    find min weight edge e = (u, v) from u ∈ C to v ∈ V \ C
    T <- T ∪ {e}
    C <- C ∪ {v}
end
```


Implementation: We use priority queue as data structure (using min-heap, and we know each operation takes &#92;(O(\log k) &#92;) where &#92;(k &#92;) is # of elements), maitain a set of weighted elements.
- Find and delete min weight element
- insert
- delete

Total cost
&#92;[
    O(n\log m + m\log m+ m\log m)  = O(m\log m) = O(m\log n)
&#92;]

In graph theory, a **cut** is a partition of the vertices of a graph into two disjoint subsets. Any cut determines a cut-set, the set of edges that have one endpoint in each subset of the partition. These edges are said to cross the cut. These edges are called **crossing edges**. Let &#92;(A\subseteq E &#92;). A cut &#92;((S,V\setminus S) &#92;) **respects** the set of edges &#92;(A &#92;) provided that no edges in &#92;(A &#92;) is a crossing edge.

**A general greedy algorithm to find an MST**
```
A <- ∅
while |A| < n-1
    (S, V\S) <- a cit that respects A
    let e be a minimum crossing edge
    A <- A ∪ {e}
end
```

## Single Source Shortest paths
**Instance**: A directed graph &#92;(G=(V,E) &#92;), a non-negative weight function &#92;(w: E\to \mathbb R^{\ge 0} &#92;), and a source vertex &#92;(u_0\in V &#92;).

**Find**: For every vertex &#92;(v\in V &#92;), a directed path &#92;(P &#92;) from &#92;(u_0 &#92;) to &#92;(v &#92;) such that &#92;(w(P)=\sum\limits_{e\in P} w(e)&#92;) is minimized.

### Dijkstra's Algorithm
Dijkstra's algorithm requires that the graph have no edge weights &#92;(< 0 &#92;); it works for directed or undirected graphs.

General step:
```
Have tree of shortest paths to all vertices in set B; initially S = {u_0}

Choose edge (x,y), x ∈ B, y ∉ B to minimize d(s, x) + w(x, y).
// Here d(s, x) is distance from s to x, which is known.

d(s,y) <- d_min
add (x,y) to tree (Parent(y) <- x)
```

![](/pics/Dijkstra.png)

picture from Prof. Lubiw's F19 CS341 notes. This is greedy in the sense that we always add the vertex with next min distance from s.

Implmentations:
- want to choose edge leaving B to minimize some values
- could make a heap of edges which has size &#92;(O(m) &#92;)
- More effcient: a heap of vertices

Keep "tentative distance" &#92;(d(v) \quad \forall v\not\in B &#92;)

Total time &#92;(O(n\log n + m\log n)=O(m\log n)  &#92;). Here it takes &#92;(n &#92;) to find min, &#92;(m &#92;) to adjust heap. Actually, there is a fancier "Fibonacci heap" that gives &#92;(O(n\log n+m) &#92;).

**Recall**: negative weight cycles are trouble. Note that negative weight edges in an undirected graph are not allowed, as they would give rise to a negative cycle (consisting of two edges) in the associated directed graph.

## Shortest Paths in a DAG
If G is a DAG, we perform a topological ordering of the vertices, the result is &#92;(v_ 1,\ldots, v_ n &#92;). Recall this is done by DFS. If v vomes before s, there is no path s->v. So throw these vertice away.

```
for i = 1 .. n
    for every edge (v_i, v_j)
        if d_i + w(v_i, v_j) < d_j then
            d_j <- d_i + w(v_i, v_j)
    endfor
endfor
```
This is &#92;(O(n+m) &#92;).
## Bellman-Ford
The Bellman-Ford algorithm solves the single source shortest path problem in any directed graph without negative weight cycles.
It is **the** original application of dynamic programming.

**Note**: if there is a negative weight cycle then shortest paths are not well-defined. Go around the cycle move and move to decrease length of path arbitrarily.

**Idea of DP for shortest paths**: If shortest uv path goes through x, then it consists of shortest ux path + shortest xv path (these are subproblems)

Here we want to compute:
&#92;[
    d_i[v] = \text{ length of the shortest path from $s$ to $v$ that uses $\le i$ edges}
&#92;]
base case: &#92;(d_1[v] = &#92;begin{cases}
0 & &#92;text{if } v=s &#92;&#92;
w(s,v) & &#92;text{if } (s,v)\in E  &#92;&#92;
   \infty& &#92;text{otherwise}
&#92;end{cases} &#92;)

and our recurrence:
&#92;[
    d_i(v)= \min &#92;begin{cases}
    d_{i-1}(v) & &#92;text{(use $\le i-1$ edges) }  &#92;&#92;
     \min\limits_{u \in &#92;left&#92;{ u: (u,v)\in E &#92;right&#92;}} (d_{i-1}(u)+w(u,v))  & &#92;text{(use $i$ edges)}
    &#92;end{cases}
&#92;]
## All-Pairs Shortest Paths
