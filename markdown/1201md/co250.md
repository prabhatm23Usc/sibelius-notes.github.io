title: CO 250 - Intro to Opt (suboptimal)
---

# Lec 1
Starting example.

*What is opt?*

Abstracting optimization problems have this form: we are given \\(A\subseteq \mathbb R^n\\) and a function \\(f:A\to\mathbb R\\). The goal is to find \\(x\in A\\) that minimizes/maximizes \\(f(x)\\).

*What are linear programs?*

Linear programs (LPs) is a class of optimization problems that can be efficiently solved using variables \\(x_1,\ldots,x_n\\), a function is **affine** if it has the form \\(a_1x_1+\ldots+a_nx_n+b\\) for some constants \\(a_1,\ldots,a_b,b\\). It is **linear** if in addition, \\(b=0\\). In vector form, if \\(x=(x_1,\ldots,x_n)^T\\) and \\(a=(a_1,\ldots,a_n)^T\\), then \\(a^Tx+b\\) is affine, and \\(a^Tx\\) is linear.

A linear program has objective function \\(\max f(x)\\) or \\(\min f(x)\\) where \\(f(x)\\) is affine, and constraints of the form \\(g(x)\le b\\), or \\(g(x)\ge b\\) for some linear \\(g\\), constraint \\(b\\).

# Lec 2
LP formulations and IP formulations.

IP is a linear program except we restrict variables to take on only integer values.

# Lec 3
IP formulations.

optimization on graphs.

A graph \\(G=(V,E)\\) consists of a set of objects \\(V\\) called vertices and a collection of unordered paris of vertices \\(E\\) called edges.

# Lec 4
## maximum weight matching problem

\\[
\begin{array}{ll}
\max & \begin{array}{l}w^T x\end{array}\\\\
\text{s.t.} & \begin{array}{lll}
Ax\le 1\\\\
x_e\in \\\\{0,1\\\\} \quad \forall e\in E
\end{array}
\end{array}
\\]
The constraints  force \\(x_e\le 1\\) so we can reduce this to \\(x_e\ge 0,x_e\in\mathbb Z\\) for all \\(e\in E\\).


## shortest path problem

**Variables**:  Define \\(x_e\\) for each \\(e\in E\\) to represent \\(x_e=\begin{cases}
1 & \text{if } e \text{ is in the path} \\\\
0 & \text{otherwise}
\end{cases}\\)

\\[
\begin{array}{ll}
\min & \begin{array}{l}w^Tx\end{array}\\\\
\text{s.t.} & \begin{array}{lll}
x_e\in \\\\{0,1\\\\}\quad \forall e\in E
\end{array}
\end{array}    
\\]



Given \\(W\subseteq V\\), the **cut induced by** \\(W\\) is the set of all edges with exactly one endpoint in \\(W\\). Notation: \\(\delta(W)\\).
\\(\delta(W) = \\\\{uv\in E: u\in W, v\not\in W\\\\}\\). This \\(\delta(W)\\) is an \\(s,t\\)-cut
 if \\(s\in W\\) and \\(t\not\in W\\).

**Key observation**: Given an \\(s,t\\)-cut \\(\delta(W)\\), any \\(s,t\\)-path must use at least one edge in \\(\delta(W)\\).

**One possible constraint**: For each \\(s,t\\)-cut, at least one edge must be in the path.
\\[
    \sum_{e\in\delta(W)}x_e\ge 1 \qquad \forall s,t\text{-cuts }\delta(W)
\\]

# Lec 5
**Problem:** A feasible solution may not be a \\(s,t\\)-path. For example, \\(x_e=1, \quad \forall e\in E\\).

**Resolution**:
1. If a set of edges intersets every s,t-cut, then this set of edges must contain an s,t-path. (i.e., it has an s,t-path plus possibly other edges).
2. We assumed \\(w_e>0\\) for all \\(e\in E\\). If we have edges that are not part of an s,t-path, we can remove them and get a better solution (lower obj value).

Therefore, an optimal solution must correspond to an s,t-path.

By the same argument, we don't need \\(x_e\le 1\\). Any higher values of \\(x_e\\) would not be optimal.

**Full shortest path IP**
\\[
    \begin{array}{ll}
    \min & \begin{array}{l}w^T x\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    \sum_{e\in\delta(W)}x_e\ge 1 & \forall s,t\text{-cuts }\delta(W)\\\\
    x_e\ge 0,\quad x_e\in \mathbb Z&\forall e\in E\end{array}
    \end{array}
\\]

## Nonlinear programming
NLP

**General form**
\\[
    \begin{array}{ll}
    \min & \begin{array}{l}f(x)\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    g(x_1)\le 0\\\\
    g(x_2)\le 0 \\\\
    \vdots \\\\
    g_m(x)\le 0
    \end{array}
    \end{array}
\\]
\\(f:\mathbb R^n\to\mathbb R\\), \\(g_i:\mathbb R^n\to\mathbb R\\) for each \\(i\\).

# Lec 6
**Proposition**: The system \\(Ax=b, x\ge 0\\) is infeasible if \\(\exists y\\) such that \\(y^T A\ge 0\\) and \\(y^T b<0\\).

**Defn** A max LP is *unbounded* if \\(\exists\\) a series of feasible solutions \\(x(t)\\) such that the objective value approaches \\(\infty\\) as \\(t\to\infty\\).

**Proposition**: The LP \\(\begin{array}{ll}
\max & \begin{array}{l}c^Tx\end{array}\\\\
\text{s.t.} & \begin{array}{lll}
Ax=b\\\\
x\ge 0
\end{array}
\end{array}\\) is unbounded if there exists feas sol \\(\bar x\\) and a vector \\(d\\) such that \\(Ad=0,d\ge 0,c^Td>0\\).

**Fundamental Theorem of Linear Programming**: For any LP, exactly one of these holds: infeasible, unbounded, has an opt solution.

## SEF
Standard equality form

\\[
    \begin{array}{ll}
    \max & \begin{array}{l}c^Tx+\bar z\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    Ax=b\\\\
    x\ge 0
    \end{array}
    \end{array}
\\]
# Lec 7
## SEF
Equivalent LPs

3 variations
1. min to max
2. Ineq: \\(x_1-x_2\le 5 \to x_1-x_2+x_3=5, x_3\ge 0\\) slack variable
3. Free var. Suppose \\(x_1\\) can take any real values. Introduce \\(x_1^+,x_1^-\\) and replace all instances of \\(x_1\\) with \\(x_1^+-x_1^-\\), where \\(x_1^+,x_1^-\ge 0\\).

# Lec 8
## Bases
Let \\(A\\) be an \\(m\times n\\) matrix with full row rank. We index the columns from 1 to \\(n\\). We say \\(B\subseteq \\\\{1,\ldots,n\\\\}\\) is a **basis** if \\(A_B\\) is invertible.

<div class='ex'>
<div class="ex-title">
BS and BFS
</div>

<div class='ex-content'>
<p>**Basic Solution** of \\(Ax=b\\) determined by \\(B\\): A vector \\(\bar x\\) is a basic solution of \\(Ax=b\\) for a basic \\(B\\) if \\(A\bar x=b\\) and \\(\bar x_N=0\\), where \\(\bar x_N\\) is the vector formed by the nonbasic variables. That is, \\(N:=\\\\{1,\ldots,n\\\\}\setminus B\\). </p>
<p>A vector \\(\bar x\\) is a BFS of \\(\\\\{Ax=b,\quad x\ge 0\\\\}\\) if it is a basic solution of \\(Ax=b\\) determined by \\(B\\) that also satisfies \\(\bar x\ge 0\\).</p>
</div>
</div>

In general, \\(Ax = A_Bx_B +A_Nx_N\\). For a basic solution, \\(Ax=A_Bx_B=b\\). This solution is unique (by lin alg).

## Canonical form
An LP in SEF is in canonical form w.r.t a basis \\(B\\) if \\(A_B=I\\) and \\(c_B=0\\).

# Lec 9
## Simplex
**Main idea**: go from feasible basis to feasible basis, attempting to raise obj val along the way.

1. Start with a feas. basis \\(B\\).
2. Rewrite the LP in canonical form w.r.t. \\(B\\).
3. Pick an entering var.<br>Pick a non-basic var \\(x_k\\) where \\(c_k>0\\).
4. Pick a leaving var.
    - Choose \\(t =\min \left\\\\{ \dfrac{b_i}{A_{ik}}: A_{ik}>0\right\\\\}\\)
    - our leaving var is \\(x_e\\), our new basis is \\(B'=B\cup \left\\\\{k\right\\\\} \setminus \left\\\\{e\right\\\\}\\)
5. Repeat step 2.

# Lec 10
an example of cycling

## Termination of simplex
**Degenerate iterations**: objective value does not change, BFS does not change.

<div class='ex'>
<div class="ex-title">
Degenerate iterations
</div>

<div class='ex-content'>
\\[
    \begin{array}{ll}
    \max & \begin{array}{l}\begin{pmatrix}
    1 & 0 & 0 & 0
    \end{pmatrix}x\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
\begin{pmatrix}
3 & 2 & 1 & 0\\\\
1 & 1 & 0 & 1
\end{pmatrix}x = \begin{pmatrix}
0 \\\\2
\end{pmatrix}
    \\\\
    x\ge 0
    \end{array}
    \end{array}
\\]
Basis \\(B=\left\\\\{3,4\right\\\\}\\), BFS \\(\begin{pmatrix}
0 & 0 & 0 & 2
\end{pmatrix}^T\\)

<p>Entering var \\(x_1\\). Set \\(x_1=t\\). \\(t=\min \left\\\\{ \dfrac{0}{3}, \dfrac{2}{1}\right\\\\}=0\\). (No change in obj or BFS)</p>

<p>Leaving var \\(x_3\\)</p>

<p>New basis \\(B=\left\\\\{1,4\right\\\\}\\). BFS \\(\begin{pmatrix}
0 & 0 & 0 & 2
\end{pmatrix}^T\\)</p>
<p>This is a degenerate iteration.</p>
</div>
</div>

## Two-phase simplex
Form an **auxillary LP** with an obvious BFS. Solve this auxillary LP using simplex. The result of simplex will tell us if a BFS exists or if it is infeasible.

1. For constraints whose RHS is negative, multiply by -1. Then RHS \\(\ge 0\\).
2. Add new aux vars, one for each constraint. They form a basis that is feasible.<br>**Key concept**: The orignal LP has a feasible solution iff the aux LP has a feasible sol where all aux vars are 0.
3. We can determine whether or not such a soln exists by maximizing the sum of the negatives of all aux vars.

**Note**: Aux is feas and bounded by 0. So it has an opt solution.

**Proposition**: An LP has a feasible solution iff its aux LP has opt val 0.

# Lec 11
## Tableau method
**Main idea**: simpler for doing simpler by hand. Use a matrix to represent all data in LP. Use row reductions.

Geometry

# Lec 12
Hyperplane. Halfspace. Polyhedron.

Extreme points.

## Characterizations of extreme points
**Theorem** Let \\(P=\left\\\\{x\in \mathbb R^n: Ax\le b \right\\\\}\\) be a polyhedron, and \\(\bar x\in P\\). Let \\(A^=x=b^=\\) be the set of all tight constraints for \\(\bar x\\). Then \\(\bar x\\) is an extreme point of \\(P\\) iff \\(rank(A^=)=n\\).

**Theorem** Let \\(P=\left\\\\{x\in \mathbb R^n: Ax\le b, x\ge 0 \right\\\\}\\) where  \\(A\\) has full row rank, and let \\(\bar x\in P\\). Then \\(\bar x\\) is an extreme point of \\(P\\) iff \\(\bar x\\) is a basic feasible solution of \\(Ax=b\\).

# Lec 13
## Dual linear programs
Motivation: certificate of optimality

# Lec 14
## Strong duality
SEF version. Prove it using simplex.

# Lec 15 & Lec 16
Another version of strong duality theorem: If (P) and (D) are both feasible, then both (P), (D) have optimal solutions with the same optimal values.

## Complementary slackness
- \\(x_i=0\\) or the corresponding dual constraint is tight; and
- \\(y_j=0\\) or the corresponding dual constraint is tight.

For equality constraints, they are always tight for feasible solutions. So we don't include them CS conditions.

**Complementary slackness theorem**: Let (P), (D) be a primal-dual pair. Let \\(\bar x, \bar y\\) be feasible for (P), (D) respectively. The \\(\bar x,\bar y\\) are optimal for (P), (D) respectively iff \\(\bar x,\bar y\\) satisfy all complementary slackness conditions.

**Defn**: \\(x^1,\ldots,x^k\in\mathbb R^n\\). The cone generated by these vectors is \\(C=\left\\\\{\lambda_1x^1+ \ldots + \lambda_k x^k: \lambda_i \ge 0, \forall i\right\\\\}\\).

**Theorem**: Let \\(\bar x\\) be feasible for \\(\max
    \left\\\\{c^T x: Ax\le b \right\\\\} \\). Then \\(\bar x\\) is optimal iff \\(c\\) is in the cone of tight constraints for \\(\bar x\\).

## Farkas' lemma
Prove it using strong duality.

# Lec 17

## Shortest paths problem
**Problem** Given a graph \\(G=(V,E)\\) with two distinct specified vertices \\(s,t\\) and positive edge lengths \\(c_e\\), find a shortest \\(s,t\\)-path in \\(G\\).
\\[
    \begin{array}{ll}
    \min & \begin{array}{l}w^T x\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    \sum_{e\in\delta(W)}x_e\ge 1 & \forall s,t\text{-cuts }\delta(W)\\\\
    x_e\ge 0,\quad x_e\in \mathbb Z&\forall e\in E\end{array}
    \end{array}
\\]
One var \\(x_e\\) for each edge \\(e\\) to indicate if the edge is in the path.

constraints: sum of \\(x\\)'s in a cut is at least 1.

...

*Why an algorithm?*

The number of constraints is the same as the number of \\(s,t\\)-cuts, which is \\(2^{n-2}\\), which is exponential. (\\(n\\) vertices) Not efficient to solve using simplex. We will give an algorithm based on duality theory that is much faster.

**LP relaxation**: Drop integrality constraints. If we run simplex, we might get a fractional solution. Our algorithm will ensure that the soln is integral.

## Dual of the shortest paths problem
**obj**: sum of all \\(y\\)-values

**constraints for** \\(e\\): coeff 1 on cuts that contain \\(e\\)

general dual LP for the shortest paths problem:
\\[
    \begin{array}{ll}
    \max & \begin{array}{l}e^T y\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    \sum (y_S: \delta(S) \text{ is an s,t-cut containing } e) \le c_e & \forall e\in E\\\\
    y\ge 0
    \end{array}
    \end{array}
\\]

Every \\(s,t\\)-path must cross all \\(s,t\\)-cuts. So the length of each \\(s,t\\)-path is at least the sum of all \\(y\\)-values.

This is also a consequence of weak duality: any feasible \\(y\\) has obj value at most any feasible \\(x\\) (path): Any feasible \\(y\\) provides a lower bound on the length of any \\(s,t\\)-path.


# Midterm 2
Midterm.2 is on 2020, March.12 (Thu) 7-9 pm on the MC 4th floor.


Coverage:
- definitions about LPs (linear programming) at the start of chapter 1.2 (the LP formulations of ch.1.2 are not relevant for Midterm.2)
- chapter 2 (solving linear programs) with focus on ch.2.5-2.8
- chapter 4 (duality theory)
- Ass.3 & 4 and PAs 2, 3, 4

2.5-2.8
- 2.5: The simplex algorithm
- 2.6: Finding feasible solutions
- 2.7: Simplex via tableaus
- 2.8: Geometry

4
- 4.1: Weak duality
- 4.2: Strong duality
- 4.3: A geometric characterization of optimality
- 4.4: Farkas' lemma

## PA 2
**Exercise 1**: Outcomes & certificates for LPS
<div class='ex'>
<div class="ex-title">
Unboundedness theorem
</div>

<div class='ex-content'>
\\[
    \begin{array}{ll}
    \max & \begin{array}{l}c^Tx\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    Ax\le b\\\\
    \end{array}
    \end{array}
\\]
is unbounded iff (P) is feasible and \\(\exists d \in \mathbb R^n: c^Td>0\\) and \\(Ad \le 0\\).
</div>
</div>

In this question:
\\[
    \begin{array}{ll}
    \max & \begin{array}{l}c^Tx\end{array}\\\\
    \text{s.t.} & \begin{array}{lll}
    Ax=0\\\\
    x\ge 0
    \end{array}
    \end{array}
\\]
\\(\exists d\\) is feasible and \\(c^Td>0\\) which satisfies \\(Ad=0,d\ge 0\\).

**Exercise 2**: Outcomes in shortest paths
