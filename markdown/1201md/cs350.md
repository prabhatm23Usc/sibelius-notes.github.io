title: CS 350 - Operating Systems
---
miscellaneous notes... Also, check my [help page](../cs350help/)

Lesley's lectures recording starts from lec 7.
# Intro
OS:
- manages resource
- creates execution environments.

Three views:
1. Application view: provide services
    - part cop: provides protection from program errors. part facilitator: abstract interface to underlying system
    - What services?
        - resources
        - interfaces
        - isolates running programs
2. System view: solve problems
    - manages the hardware resources
    - allocates resources
    - controls the access to or sharing of resources among programs.
3. Implementation view: how is it built?
    - **concurrent**: multi progs or seqs of instrs *running, or appearing to run, at the same time*.
    - **real-time**: must respond to an event in a specific amount of time.

**kernel**: The operating system kernel is the part of the operating system that responds to system calls, interrupts and exceptions.

**operation system**: The operating system as a whole includes the kernel, and may include other related programs that provide servicesfor applications.  This may include things like:
- utility programs (e.g. disk defragmenter, task manager)
- command interpreters (e.g. cmd.exe in Windows, bash in Linux)
- programming libraries (e.g. POSIX threads in Linux)

**monolithic kernel**: the entire operating system (which includes the device drivers, file system, and the application IPC) is working in kernel space. "everything and the kitchen sink" is a part of the
kernel. This includes device drivers, file system, virtual memory, etc.

**microkernel**: only absolutely necessary components are a part of the
kernel. All other elements are user programs.

**real-time OS**: an OS with stringent event response times,
guarantees, and preemptive scheduling.

The **execution environment** provided by the OS includes a variety of
**abstract entities** that can be manipulated by a running program.

# Threads
seq of instructions.

a single program can have
- diff threads responsible for different roles
- multi threads --- same roles

Reasons we use threads:
- Efficient Use of Resource
- parallelism
- responsiveness
- priority
- modularization

# Synchronization

> Lesley's recordings start here.

We left last class: semaphores and CV. Different primitives for concurrency problem.
- Semaphore:
    - any number of resources. `P` acquire, `V` release. Use as a lock. Keep in mind it's not lock. There's no built-in protection for it, no track of ownership: someone else tries to release **binary** semaphore on me, they can, and we have race condition.
    - **counting**: keep counting # of resources
    - **barrier**: force one thread to wait for others to complete before we proceed. Not separate implementation.
    - keep in mind do not touch the counter directly. It's a shared resource.
- CV: you are inside critical section. You really need condition to be true to proceed. But the lock you own it the lock you are using to protect the shared variable that has unique value. CV lets us do simultaneously safely let go of the lock and fall asleep so that another thread can modify the condition and wake us back up.<br>
Most of the type we are using: when we are woken back up, we need to recheck the condition.

## Other sources of Race conditions
The previous RC is because of the code you wrote.

**memory models** describe how thread access to memory in shared regions behave. a memory model tells the compiler and CPU which optimizations can be performed

**compiler**: it does optimization. Reduce the # of assembly instrs: load and stores.
```c++
int sharedTotal = 0;
int FuncA() {
    //... code that uses sharedTotal ...
}
int FuncB() {
    //... code that uses sharedTotal ...
}
```
Instead of go to RAM, much more efficient to keep it in register: register allocation. Here's the problem: It doesn't know if A and B run at the same time. If one put in `$3` one in `$8`. Big race condtion. There are also others optimization.

Always load/store var from RAM, not reordering: `volatile`. Disable compiler optimizations, but not solve race conditions in your codes.

**CPU**: fetch the program counter, decode it, execute it and move on. But it's more complex: pipeline, branch prediction, reorder instrs... It also has memory model and so that you can notify the CPU: multi-threaded code is going on here. Barrier or fence instrs to entry gate: CPU stops rearranging. And until end gate, turn on opt back on. Don't need to worry in OS161.


*In class problem: semaphore to CV*
<table>
    <thead>
        <tr>
            <th>Global Vars</th>
            <th>Initialization</th>
            <th>Function `func1`</th>
            <th>Function `func2`</th>
        </tr>
    </thead>
<tbody>
<tr>
<td>
<pre>
struct semaphore \*sa;
struct semaphore \*sb;
struct semaphore \*sc;
</pre>
</td>
<td>
<pre>
sa = sem_create("A", 1);
sb = sem_create("B", 1);
sc = sem_create("C", 0);
</pre>
</td>
<td>
<pre>
void func1() {
    P(sa);
    funcA();
    V(sa);
    P(sc);
}
</pre>
</td>
<td>
<pre>
void func2() {
    P(sb);
    funcB();
    V(sb);
    P(sc);
}
</pre>
</td>
</tr>
</tbody>
</table>

Re-implement `func1` and `func2` using lock and cv.

**Solution**: func1 is consumer, func2 is producer.

```c++
lock A, B, C;
CV cv;
count = 0;

func1 {
    lock_acq(A)
        funcA()
    lock_rel(A)

    lock_acq(C)
        count--
        if (count < 0) cv_wait(cv, C)
    lock_rel(C)
}

func2 {
    lock_acq(B)
        funcB()
    lock_rel(B)

    lock_acq(C)
        if (count < 0) cv_signal(cv, C)
        count++
    lock_rel(C)
}
```

## Deadlocks
```c++
lock lockA, lockB;

int FuncA() {
    lock_acquire(lockA)
    lock_acquire(lockB)
    ...
    lock_release(lockA)
    lock_release(lockB)
}

int FuncB() {
    lock_acquire(lockB)
    lock_acquire(lockA)
    ...
    lock_release(lockB)
    lock_release(lockA)
}
```

- Thread 1 executes `lock_acquire(lockA)`
- Thread 2 executes `lock_acquire(lockB)`
- Thread 1 executes `lock_acquire(lockB)`
- Thread 2 executes `lock_acquire(lockA)`

Deadlock only shows up under certain order of thread execution. It is very difficult to detect: between problematic wait and wait on purpose.

Generally, it happens when multiple threads, each acquire multiple resources.
1. don't try to aquire a lock if you have already owned.
2. Two strategies

**No hold and wait**: while you own the resources, no wait (no block, no spin).
<br> Being able to aquire all resources at once. We need special implementation of lock to support.

If you can't acq a lock, you can't fall asleep. Special implementation of acq.

```c++
// true if you get the lock
// false if cannot, but do not go to sleep.
bool try_acq(lk) {
    acq(lk->spin)
        if (lk->held) {
            release(lk->spin)
            return false
        }
        lk->held =  true
        lk->owner = me
    release(lk->spin)
    return true
}
```

Solution to previous deadlock:

```c++
acq(A) // I own nothing and safely acquire

while (!try_acq(B)) {
    release(A)
    // if you want to improve the performance, put yield here
    acq(A)
}
```

But it's nasty if we want acq lots of things, also it's spinning.

**Resource ordering**: assign every single resource a single number. Acquire them only in strictly increasing order. There's problem if different programmers have different rules.

*In class problem: queuexfer*
> Suppose that a threaded program has N queues of items. The program needs to support an operation called `Transfer(i,j)`. Each call to `Transfer` will transfer a single item from the i-th queue to the jth queue,
unless there is nothing in the i-th queue, in which case the call will not affect the queues.
<br>The program will have multiple concurrent threads, each of which may call `Transfer` zero or more times.
<br>How would you use locks to ensure that `Transfer` operations are atomic? Specifically, how many locks
would you use, what would each lock protect, and when would the locks be acquired and released to ensure
that transfers are atomic?

One way: no hold and wait. Downside: cannot both lock at the same time, busy wait: spin.

Alternate: resource ordering.
```c++
Transfer(Q_a, Q_b) {
    // check resource number
    if (a < b) {
        acq(qa)
        acq(qb)
    } else {
        acq(qb)
        acq(qa)
    }
}
```
Downside: you need to sort if you acq all resources \\(\Theta(n\log n)\\).

# Process
is an is an environment in which an application program runs.

includes virtualized resources that its program can use: one (or more) threads

each programâ€™s process *isolates* it from other programs in other processes

## fork
creates a brand new process (the child) that is a clone of the original (the parent)
- new process structure
- new address space
- new thread array
- new PID
clone
- content of address space

## _exit
terminate the calling process. Not necessarily disappear: stop executing, address space get cleaned, but if it has parents, that parent is alive. Parents want to figure out why child dies. Leave behind a msg for parent.

## waitpid
offer synchronization between processes. Cause the caller to wait for the PID process to terminate. Restricted to: parent can only wait for their children to die.

Children cannot wait for their parents. If they die, they are old.

## execv
Now, the last of the five system calls: execv. It does not create a new process.

It changes the program and a existing process is running. Process structure is same, but the address space has changed.

`Hello world` program, and call `execv matlab`.

Create a new address space, and load the program into the new address space.

Parent child relationship: If you go home tonight, and dye your hair in green, your parent may not like it. But they cannot change genetically they are your parents. The same is true for processes: you can change the program that you are running but you cannot change parent-child relationship.

Example from slides:
```c++
int main()
{
    int rc = 0;
    char *args[4];

    args[0] = (char *) "/testbin/argtest";
    args[1] = (char *) "first";
    args[2] = (char *) "second";
    args[3] = 0; // null terminator

    rc = execv("/testbin/argtest", args); // takes two parameters
    printf("If you see this execv failed\n");
    printf("rc = %d errno = %d\n", rc, errno);
    exit(0);
}
```

takes two parameters. Many times you need command line arguments. Array of pointers.

`execv` if it succeeds, does not return. Because it successfully created the new address space and new program. We successfully loaded the program into it. The calling program will not exist if `execv` succeeded. The only time it returns is when it fails. Why would it fail? 30mb ram then run Matlab. It's possible that there's no memory left or you call the program wrongly. When you write your `execv`, you need to test for these error cases and return appropriate error codes. (but cs350 stuff don't have such tests on these).

You notice that we can't tell how many arguments there are automatically. So we use null terminator array and you are responsible for counting.

Another example. This time with fork.

```c++
int main()
{
    char *args[4];
    /* set args here */
    rc = fork(); /* returns 0 to child, pid to parent */
    if (rc == 0) {
        status = execv("/testbin/argtest",args);
        printf("If you see this execv failed\n");
        printf("status = %d errno = %d\n", status, errno);
        exit(0);
    } else {
        child_pid = rc;
        parent_code();
        p = waitpid(child_pid,&child_exit,0);
    }
}
```

Now I have two processes. Even though they are separate, but their contents are identical with the exception of value of `rc`. 0 for child, pid for parent.

If child, `execv`. Child is running different process. Parent can still wait for child to terminate. Parent child relationship is not impacted by `execv` which stays forever.

Go home and write thread fork bomb.

# System Calls
- Process management calls, e.g., fork, are called by user programms. They are also system calls.
- **System calls** are the interface between user processes and the kernel.
- The kernel code runs at the highest privilege level, where any CPU instructions can be executed.
- Program in user space cannot execute code or instructions belonging to a higher-level of privilege.

## Kernel Privilege
The CPU implements different levels (or rings) of execution
privilege as a security and isolation mechanism. Kernel code at highest level.

**Key Question**: Since application programs cannot directly call the
kernel, how does a program make a system call such as `fork`?
1. Interrupts
    - Interrupts are raised by devices (hardware)
    - An interrupt causes the CPU to transfer control to a fixed location in memory (specified by the designers of the CPU) where an interrupt handler must be located.
    - Interrupt handlers are part of the kernel.
2. Exceptions
    - conditions that occur during the execution of a program instruction.
    - The CPU handles exceptions like it handles interrupts:
        - Control is transferred to a fixed location, where an exception handler is located.
        - The processor switches to privileged execution mode.
    - In OS/161 *the same routine is used to handle exceptions and interrupts*.

When CPU receives interrupt or exception, your program stops executing and exception/interrupt handler is called, part of kernel code. Then CPU switches from unprivileged mode to privileged mode, so now we can execute kernel's code. Produces the trapframe: storing every single reg value (including special ones) so we can return to the exact point of program execution after we handle.


Extra: [Spectre and Meltdown Papers](https://meltdownattack.com/).



**Key Question**: There is only one `syscall` exception, `EX_SYS`. So how does the OS distinguish between a `fork` and `getpid` system call?

*system call codes*
- The kernel expects the code to be placed in a specified location before executing `syscall` (for OS/161 on MIPS, reg `v0`)
- the codes and code location are part of the kernal ABI (Application Binary Interface)

ABI is not secret because we need user land to know that info and it absolutely tells nothing what's happening in the kernel -- blackbox.

Example:
- `li v0, 0` where 0 is the syscall code for `fork`.
- Syscall parameters: load into regs `a0` to `a3`. If more, put into stack or heap, and put the address here.
- Use `syscall` to raise exception.

Return two values:
- reg `a3`: success/fail
- reg `v0`: return value/error code

## User and Kernel Stacks
Every OS/161 process thread has **two** stacks, although it only uses one at a time.

The only thing that goes into user stack us the user application stack. But before we save the trapframe, we must change the stack pointer from user stack to kernel stack.
1. The User (Application) Stack is used while the thread is executing application code.
    - Saw this in [CS 241](/19-05/CS241/).
    - The kernel creates this stack when it sets up the virtual address space for the process (or thread if the OS supports multi-threaded code).
2. The Kernel Stack is used while the thread is executing kernel code, i.e. after an exception or interrupt.
    - This stack is a kernel structure (i.e. it is located in the kernelâ€™s address space).
    - It also holds trap frames and switch frames (because it is the kernel that creates trap frames and switch frames)

## Exception Handling
* first to run assembly code, `common_exception`
    - save stack pointer
    - switches SP to point to the thread's kernel stack,
    - carefully saves app state and address of the instruction,
    - calls `mips_trap`, passing a pointer to the trap frame as an arg.
* After `mips_trap` is finished, the `common_exception` handler will
    - restore application's state
    - jump back to application instruction that was interrupted and switch back to unprivileged execution mode.
* See `kern/arch/mips/locore/exception-mips1.S` (assembly file)

### mips_trap
determines what type of exception it is by looking at the exception code.

(there is a separate handler in the kernel for each type of exception.) Based on that exception code, call appropriate handler.
- interrupt? call `mainbus_interrupt`
- address translation exception? `vm_fault`
- system call? call `syscall` (kernel function), passing it the trap
frame pointer
- `kern/arch/mips/syscall/syscall.c`

See `kern/arch/mips/locore/trap.c`

**One important thing**: when exception raised, one of the first thing `common_exception` does it to disable the interrupt on CPU. When we call `mips_trap`, interrupt exceptions are off for now.
- If it was actually an interrupt, they stay off until  the hardware has been handled.
- If not, don't have to call `mainbus_interrupt` to handle it, then we are ok to be interrupted again. It is not hardware interrupt, then we take interrupt exceptions back on.

**increase program counter**: if we don't do this, the system call exception will be raised over and over again. We are halting execution and doing sth else, thus we need manully. 4 byte.

Kernel is just a program, a sequence of instructions.

Two type of calls:
- procedure calls: used by apps to execute other application code,
- sys calls: exec kernel code.

## Multiprocessing
- The OS ensures that *processes are isolated from one another*.
- Interprocess communication should be possible.

Keep in mind, it's not processes that run. Threads execute. Process has to have a thread in order to execute, so we really are talking about multithreads. Now we have a pool of threads, which belong to different processes. Only when quantum expires, we do context switch. (Timer interrupt)

## Stack Diagrams
In the next few minutes, I'm gonna show you stack diagrams because you'd better bet they are going to show up on your exams.

`mips_trap`'s job is to figure out what kind of exception that actually raised. Then call the handler that is specific to this exception. Now we are going to execute `mips_trap`. Now after we check that if it's an interrupt or not, then it realizes that it is not an interrupt, then `mips_trap` will turn exceptions and interrupts back on. It means that while we are executing our sys call, we CAN be interrupted. KEEP THAT IN MIND.

Look at `v0` and that's going to tell you which syscal we actually want to run (a great big old `switch` statement). We want `sys_fork`. Now interrupts are on which means you can be preempted while executed this fork.

So now what happens to our stack: If we have a timer interrupt. First thing you see is trap frame (produced by `common_exception`). Push a trapframe onto the kernel stack. Since we are already in privilege mode and on kernel stack, you actually know the `common_exception` code. If we are on kernel stack, we don't do anything but just save the trapframe right. Then call `mips_trap` to figure out what just happened. It's `mainbus_interrupt`. It's hardware interrupt. While they are handling interrupts from hardware, we don't want to handle other hardware interrupts because this is the behaviour that is outside the control that thread is running and we don't to disrupt it for too long so generally leave it off.

In `mainbus_interrupt`, we discover it's the clock. Call interrupt handler for the clock: exceed schedule quantum, I'd better preempt you. So call `thread_yield` -> `thread_switch` -> `switch_frame`. Context switch occurs. Popping off the stack, then returns to ... Then go back to `common_exception` where we restore the trapframe. Btw, we are turning the interrupts back on. Then back to user stack, reset the CPU back to unprivileged mode and now we go back to have a process to thread running its regular user mode. Similar to multithreads, but we have two stacks.

Now suppose we don't have interrupt. Return to syscall. At the very end of syscall, set return value and success/failure values for that system. Zero: success; One: failure. The last thing in syscall dispatcherï¼ˆè°ƒåº¦ï¼‰, **increment program counter** because when the exception is raised we didn't actually increment it.
```c++
if (err) { /* err */
    tf->tf_v0 = err;
    tf->tf_a3 = 1;
} else { /* no err */
    tf->tf_v0 = retval;
    tf->tf_a3 = 0;
}

/* advance PC */
tf->tf_epc += 4;
```
`mips_trap` returns to `common_exception`. The trapframe data is
restored. Switch from kernel to user stack. Switch to unprivileged
mode (`rfe`: magical instruction). User code continues execution.

- These diagrams are always on either midterm or final.
- It is not possible for you to have two track frames back-to-back in OS/161. Reason for that is because when the exception is raised at the CPU, interrupts are turned off and they do not come back on again until at least halfway through `mips_trap` which means that each trapframe must be separated by at least `mips_trap`.

## Inter-Process Communication (IPC)
Processes can talk to each other. IPC is a family of methods used to send data between processes.

File, Socket, Pipe, Shared Memory, Message Passing/Queue.

---
Lec 11 ...
